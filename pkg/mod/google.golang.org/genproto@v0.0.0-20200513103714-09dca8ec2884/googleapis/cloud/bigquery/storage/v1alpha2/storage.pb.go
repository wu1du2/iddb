// Code generated by protoc-gen-go. DO NOT EDIT.
// source: google/cloud/bigquery/storage/v1alpha2/storage.proto

package storage

import (
	context "context"
	fmt "fmt"
	math "math"

	proto "github.com/golang/protobuf/proto"
	_ "github.com/golang/protobuf/ptypes/empty"
	timestamp "github.com/golang/protobuf/ptypes/timestamp"
	wrappers "github.com/golang/protobuf/ptypes/wrappers"
	_ "google.golang.org/genproto/googleapis/api/annotations"
	status "google.golang.org/genproto/googleapis/rpc/status"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status1 "google.golang.org/grpc/status"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package

// Request message for `CreateWriteStream`.
type CreateWriteStreamRequest struct {
	// Required. Reference to the table to which the stream belongs, in the format
	// of `projects/{project}/datasets/{dataset}/tables/{table}`.
	Parent string `protobuf:"bytes,1,opt,name=parent,proto3" json:"parent,omitempty"`
	// Required. Stream to be created.
	WriteStream          *WriteStream `protobuf:"bytes,2,opt,name=write_stream,json=writeStream,proto3" json:"write_stream,omitempty"`
	XXX_NoUnkeyedLiteral struct{}     `json:"-"`
	XXX_unrecognized     []byte       `json:"-"`
	XXX_sizecache        int32        `json:"-"`
}

func (m *CreateWriteStreamRequest) Reset()         { *m = CreateWriteStreamRequest{} }
func (m *CreateWriteStreamRequest) String() string { return proto.CompactTextString(m) }
func (*CreateWriteStreamRequest) ProtoMessage()    {}
func (*CreateWriteStreamRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_f4f9d0517c05d712, []int{0}
}

func (m *CreateWriteStreamRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CreateWriteStreamRequest.Unmarshal(m, b)
}
func (m *CreateWriteStreamRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CreateWriteStreamRequest.Marshal(b, m, deterministic)
}
func (m *CreateWriteStreamRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CreateWriteStreamRequest.Merge(m, src)
}
func (m *CreateWriteStreamRequest) XXX_Size() int {
	return xxx_messageInfo_CreateWriteStreamRequest.Size(m)
}
func (m *CreateWriteStreamRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_CreateWriteStreamRequest.DiscardUnknown(m)
}

var xxx_messageInfo_CreateWriteStreamRequest proto.InternalMessageInfo

func (m *CreateWriteStreamRequest) GetParent() string {
	if m != nil {
		return m.Parent
	}
	return ""
}

func (m *CreateWriteStreamRequest) GetWriteStream() *WriteStream {
	if m != nil {
		return m.WriteStream
	}
	return nil
}

// Request message for `AppendRows`.
type AppendRowsRequest struct {
	// Required. The stream that is the target of the append operation. This value must be
	// specified for the initial request. If subsequent requests specify the
	// stream name, it must equal to the value provided in the first request.
	WriteStream string `protobuf:"bytes,1,opt,name=write_stream,json=writeStream,proto3" json:"write_stream,omitempty"`
	// Optional. If present, the write is only performed if the next append offset is same
	// as the provided value. If not present, the write is performed at the
	// current end of stream.
	Offset *wrappers.Int64Value `protobuf:"bytes,2,opt,name=offset,proto3" json:"offset,omitempty"`
	// Input rows. The `writer_schema` field must be specified at the initial
	// request and currently, it will be ignored if specified in following
	// requests. Following requests must have data in the same format as the
	// initial request.
	//
	// Types that are valid to be assigned to Rows:
	//	*AppendRowsRequest_ProtoRows
	Rows                 isAppendRowsRequest_Rows `protobuf_oneof:"rows"`
	XXX_NoUnkeyedLiteral struct{}                 `json:"-"`
	XXX_unrecognized     []byte                   `json:"-"`
	XXX_sizecache        int32                    `json:"-"`
}

func (m *AppendRowsRequest) Reset()         { *m = AppendRowsRequest{} }
func (m *AppendRowsRequest) String() string { return proto.CompactTextString(m) }
func (*AppendRowsRequest) ProtoMessage()    {}
func (*AppendRowsRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_f4f9d0517c05d712, []int{1}
}

func (m *AppendRowsRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_AppendRowsRequest.Unmarshal(m, b)
}
func (m *AppendRowsRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_AppendRowsRequest.Marshal(b, m, deterministic)
}
func (m *AppendRowsRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AppendRowsRequest.Merge(m, src)
}
func (m *AppendRowsRequest) XXX_Size() int {
	return xxx_messageInfo_AppendRowsRequest.Size(m)
}
func (m *AppendRowsRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_AppendRowsRequest.DiscardUnknown(m)
}

var xxx_messageInfo_AppendRowsRequest proto.InternalMessageInfo

func (m *AppendRowsRequest) GetWriteStream() string {
	if m != nil {
		return m.WriteStream
	}
	return ""
}

func (m *AppendRowsRequest) GetOffset() *wrappers.Int64Value {
	if m != nil {
		return m.Offset
	}
	return nil
}

type isAppendRowsRequest_Rows interface {
	isAppendRowsRequest_Rows()
}

type AppendRowsRequest_ProtoRows struct {
	ProtoRows *AppendRowsRequest_ProtoData `protobuf:"bytes,4,opt,name=proto_rows,json=protoRows,proto3,oneof"`
}

func (*AppendRowsRequest_ProtoRows) isAppendRowsRequest_Rows() {}

func (m *AppendRowsRequest) GetRows() isAppendRowsRequest_Rows {
	if m != nil {
		return m.Rows
	}
	return nil
}

func (m *AppendRowsRequest) GetProtoRows() *AppendRowsRequest_ProtoData {
	if x, ok := m.GetRows().(*AppendRowsRequest_ProtoRows); ok {
		return x.ProtoRows
	}
	return nil
}

// XXX_OneofWrappers is for the internal use of the proto package.
func (*AppendRowsRequest) XXX_OneofWrappers() []interface{} {
	return []interface{}{
		(*AppendRowsRequest_ProtoRows)(nil),
	}
}

type AppendRowsRequest_ProtoData struct {
	// Proto schema used to serialize the data.
	WriterSchema *ProtoSchema `protobuf:"bytes,1,opt,name=writer_schema,json=writerSchema,proto3" json:"writer_schema,omitempty"`
	// Serialized row data in protobuf message format.
	Rows                 *ProtoRows `protobuf:"bytes,2,opt,name=rows,proto3" json:"rows,omitempty"`
	XXX_NoUnkeyedLiteral struct{}   `json:"-"`
	XXX_unrecognized     []byte     `json:"-"`
	XXX_sizecache        int32      `json:"-"`
}

func (m *AppendRowsRequest_ProtoData) Reset()         { *m = AppendRowsRequest_ProtoData{} }
func (m *AppendRowsRequest_ProtoData) String() string { return proto.CompactTextString(m) }
func (*AppendRowsRequest_ProtoData) ProtoMessage()    {}
func (*AppendRowsRequest_ProtoData) Descriptor() ([]byte, []int) {
	return fileDescriptor_f4f9d0517c05d712, []int{1, 0}
}

func (m *AppendRowsRequest_ProtoData) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_AppendRowsRequest_ProtoData.Unmarshal(m, b)
}
func (m *AppendRowsRequest_ProtoData) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_AppendRowsRequest_ProtoData.Marshal(b, m, deterministic)
}
func (m *AppendRowsRequest_ProtoData) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AppendRowsRequest_ProtoData.Merge(m, src)
}
func (m *AppendRowsRequest_ProtoData) XXX_Size() int {
	return xxx_messageInfo_AppendRowsRequest_ProtoData.Size(m)
}
func (m *AppendRowsRequest_ProtoData) XXX_DiscardUnknown() {
	xxx_messageInfo_AppendRowsRequest_ProtoData.DiscardUnknown(m)
}

var xxx_messageInfo_AppendRowsRequest_ProtoData proto.InternalMessageInfo

func (m *AppendRowsRequest_ProtoData) GetWriterSchema() *ProtoSchema {
	if m != nil {
		return m.WriterSchema
	}
	return nil
}

func (m *AppendRowsRequest_ProtoData) GetRows() *ProtoRows {
	if m != nil {
		return m.Rows
	}
	return nil
}

// Response message for `AppendRows`.
type AppendRowsResponse struct {
	// Types that are valid to be assigned to Response:
	//	*AppendRowsResponse_Offset
	//	*AppendRowsResponse_Error
	Response             isAppendRowsResponse_Response `protobuf_oneof:"response"`
	XXX_NoUnkeyedLiteral struct{}                      `json:"-"`
	XXX_unrecognized     []byte                        `json:"-"`
	XXX_sizecache        int32                         `json:"-"`
}

func (m *AppendRowsResponse) Reset()         { *m = AppendRowsResponse{} }
func (m *AppendRowsResponse) String() string { return proto.CompactTextString(m) }
func (*AppendRowsResponse) ProtoMessage()    {}
func (*AppendRowsResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_f4f9d0517c05d712, []int{2}
}

func (m *AppendRowsResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_AppendRowsResponse.Unmarshal(m, b)
}
func (m *AppendRowsResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_AppendRowsResponse.Marshal(b, m, deterministic)
}
func (m *AppendRowsResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AppendRowsResponse.Merge(m, src)
}
func (m *AppendRowsResponse) XXX_Size() int {
	return xxx_messageInfo_AppendRowsResponse.Size(m)
}
func (m *AppendRowsResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_AppendRowsResponse.DiscardUnknown(m)
}

var xxx_messageInfo_AppendRowsResponse proto.InternalMessageInfo

type isAppendRowsResponse_Response interface {
	isAppendRowsResponse_Response()
}

type AppendRowsResponse_Offset struct {
	Offset int64 `protobuf:"varint,1,opt,name=offset,proto3,oneof"`
}

type AppendRowsResponse_Error struct {
	Error *status.Status `protobuf:"bytes,2,opt,name=error,proto3,oneof"`
}

func (*AppendRowsResponse_Offset) isAppendRowsResponse_Response() {}

func (*AppendRowsResponse_Error) isAppendRowsResponse_Response() {}

func (m *AppendRowsResponse) GetResponse() isAppendRowsResponse_Response {
	if m != nil {
		return m.Response
	}
	return nil
}

func (m *AppendRowsResponse) GetOffset() int64 {
	if x, ok := m.GetResponse().(*AppendRowsResponse_Offset); ok {
		return x.Offset
	}
	return 0
}

func (m *AppendRowsResponse) GetError() *status.Status {
	if x, ok := m.GetResponse().(*AppendRowsResponse_Error); ok {
		return x.Error
	}
	return nil
}

// XXX_OneofWrappers is for the internal use of the proto package.
func (*AppendRowsResponse) XXX_OneofWrappers() []interface{} {
	return []interface{}{
		(*AppendRowsResponse_Offset)(nil),
		(*AppendRowsResponse_Error)(nil),
	}
}

// Request message for `GetWriteStreamRequest`.
type GetWriteStreamRequest struct {
	// Required. Name of the stream to get, in the form of
	// `projects/{project}/datasets/{dataset}/tables/{table}/streams/{stream}`.
	Name                 string   `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *GetWriteStreamRequest) Reset()         { *m = GetWriteStreamRequest{} }
func (m *GetWriteStreamRequest) String() string { return proto.CompactTextString(m) }
func (*GetWriteStreamRequest) ProtoMessage()    {}
func (*GetWriteStreamRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_f4f9d0517c05d712, []int{3}
}

func (m *GetWriteStreamRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_GetWriteStreamRequest.Unmarshal(m, b)
}
func (m *GetWriteStreamRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_GetWriteStreamRequest.Marshal(b, m, deterministic)
}
func (m *GetWriteStreamRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_GetWriteStreamRequest.Merge(m, src)
}
func (m *GetWriteStreamRequest) XXX_Size() int {
	return xxx_messageInfo_GetWriteStreamRequest.Size(m)
}
func (m *GetWriteStreamRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_GetWriteStreamRequest.DiscardUnknown(m)
}

var xxx_messageInfo_GetWriteStreamRequest proto.InternalMessageInfo

func (m *GetWriteStreamRequest) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

// Request message for `BatchCommitWriteStreams`.
type BatchCommitWriteStreamsRequest struct {
	// Required. Parent table that all the streams should belong to, in the form of
	// `projects/{project}/datasets/{dataset}/tables/{table}`.
	Parent string `protobuf:"bytes,1,opt,name=parent,proto3" json:"parent,omitempty"`
	// Required. The group of streams that will be committed atomically.
	WriteStreams         []string `protobuf:"bytes,2,rep,name=write_streams,json=writeStreams,proto3" json:"write_streams,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *BatchCommitWriteStreamsRequest) Reset()         { *m = BatchCommitWriteStreamsRequest{} }
func (m *BatchCommitWriteStreamsRequest) String() string { return proto.CompactTextString(m) }
func (*BatchCommitWriteStreamsRequest) ProtoMessage()    {}
func (*BatchCommitWriteStreamsRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_f4f9d0517c05d712, []int{4}
}

func (m *BatchCommitWriteStreamsRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_BatchCommitWriteStreamsRequest.Unmarshal(m, b)
}
func (m *BatchCommitWriteStreamsRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_BatchCommitWriteStreamsRequest.Marshal(b, m, deterministic)
}
func (m *BatchCommitWriteStreamsRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_BatchCommitWriteStreamsRequest.Merge(m, src)
}
func (m *BatchCommitWriteStreamsRequest) XXX_Size() int {
	return xxx_messageInfo_BatchCommitWriteStreamsRequest.Size(m)
}
func (m *BatchCommitWriteStreamsRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_BatchCommitWriteStreamsRequest.DiscardUnknown(m)
}

var xxx_messageInfo_BatchCommitWriteStreamsRequest proto.InternalMessageInfo

func (m *BatchCommitWriteStreamsRequest) GetParent() string {
	if m != nil {
		return m.Parent
	}
	return ""
}

func (m *BatchCommitWriteStreamsRequest) GetWriteStreams() []string {
	if m != nil {
		return m.WriteStreams
	}
	return nil
}

// Response message for `BatchCommitWriteStreams`.
type BatchCommitWriteStreamsResponse struct {
	// The time at which streams were committed in microseconds granularity.
	CommitTime           *timestamp.Timestamp `protobuf:"bytes,1,opt,name=commit_time,json=commitTime,proto3" json:"commit_time,omitempty"`
	XXX_NoUnkeyedLiteral struct{}             `json:"-"`
	XXX_unrecognized     []byte               `json:"-"`
	XXX_sizecache        int32                `json:"-"`
}

func (m *BatchCommitWriteStreamsResponse) Reset()         { *m = BatchCommitWriteStreamsResponse{} }
func (m *BatchCommitWriteStreamsResponse) String() string { return proto.CompactTextString(m) }
func (*BatchCommitWriteStreamsResponse) ProtoMessage()    {}
func (*BatchCommitWriteStreamsResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_f4f9d0517c05d712, []int{5}
}

func (m *BatchCommitWriteStreamsResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_BatchCommitWriteStreamsResponse.Unmarshal(m, b)
}
func (m *BatchCommitWriteStreamsResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_BatchCommitWriteStreamsResponse.Marshal(b, m, deterministic)
}
func (m *BatchCommitWriteStreamsResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_BatchCommitWriteStreamsResponse.Merge(m, src)
}
func (m *BatchCommitWriteStreamsResponse) XXX_Size() int {
	return xxx_messageInfo_BatchCommitWriteStreamsResponse.Size(m)
}
func (m *BatchCommitWriteStreamsResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_BatchCommitWriteStreamsResponse.DiscardUnknown(m)
}

var xxx_messageInfo_BatchCommitWriteStreamsResponse proto.InternalMessageInfo

func (m *BatchCommitWriteStreamsResponse) GetCommitTime() *timestamp.Timestamp {
	if m != nil {
		return m.CommitTime
	}
	return nil
}

// Request message for invoking `FinalizeWriteStream`.
type FinalizeWriteStreamRequest struct {
	// Required. Name of the stream to finalize, in the form of
	// `projects/{project}/datasets/{dataset}/tables/{table}/streams/{stream}`.
	Name                 string   `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *FinalizeWriteStreamRequest) Reset()         { *m = FinalizeWriteStreamRequest{} }
func (m *FinalizeWriteStreamRequest) String() string { return proto.CompactTextString(m) }
func (*FinalizeWriteStreamRequest) ProtoMessage()    {}
func (*FinalizeWriteStreamRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_f4f9d0517c05d712, []int{6}
}

func (m *FinalizeWriteStreamRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_FinalizeWriteStreamRequest.Unmarshal(m, b)
}
func (m *FinalizeWriteStreamRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_FinalizeWriteStreamRequest.Marshal(b, m, deterministic)
}
func (m *FinalizeWriteStreamRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_FinalizeWriteStreamRequest.Merge(m, src)
}
func (m *FinalizeWriteStreamRequest) XXX_Size() int {
	return xxx_messageInfo_FinalizeWriteStreamRequest.Size(m)
}
func (m *FinalizeWriteStreamRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_FinalizeWriteStreamRequest.DiscardUnknown(m)
}

var xxx_messageInfo_FinalizeWriteStreamRequest proto.InternalMessageInfo

func (m *FinalizeWriteStreamRequest) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

// Response message for `FinalizeWriteStream`.
type FinalizeWriteStreamResponse struct {
	// Number of rows in the finalized stream.
	RowCount             int64    `protobuf:"varint,1,opt,name=row_count,json=rowCount,proto3" json:"row_count,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *FinalizeWriteStreamResponse) Reset()         { *m = FinalizeWriteStreamResponse{} }
func (m *FinalizeWriteStreamResponse) String() string { return proto.CompactTextString(m) }
func (*FinalizeWriteStreamResponse) ProtoMessage()    {}
func (*FinalizeWriteStreamResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_f4f9d0517c05d712, []int{7}
}

func (m *FinalizeWriteStreamResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_FinalizeWriteStreamResponse.Unmarshal(m, b)
}
func (m *FinalizeWriteStreamResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_FinalizeWriteStreamResponse.Marshal(b, m, deterministic)
}
func (m *FinalizeWriteStreamResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_FinalizeWriteStreamResponse.Merge(m, src)
}
func (m *FinalizeWriteStreamResponse) XXX_Size() int {
	return xxx_messageInfo_FinalizeWriteStreamResponse.Size(m)
}
func (m *FinalizeWriteStreamResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_FinalizeWriteStreamResponse.DiscardUnknown(m)
}

var xxx_messageInfo_FinalizeWriteStreamResponse proto.InternalMessageInfo

func (m *FinalizeWriteStreamResponse) GetRowCount() int64 {
	if m != nil {
		return m.RowCount
	}
	return 0
}

// Request message for `FlushRows`.
type FlushRowsRequest struct {
	// Required. The stream that is the target of the flush operation.
	WriteStream string `protobuf:"bytes,1,opt,name=write_stream,json=writeStream,proto3" json:"write_stream,omitempty"`
	// Ending offset of the flush operation. Rows before this offset(including
	// this offset) will be flushed.
	Offset               int64    `protobuf:"varint,2,opt,name=offset,proto3" json:"offset,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *FlushRowsRequest) Reset()         { *m = FlushRowsRequest{} }
func (m *FlushRowsRequest) String() string { return proto.CompactTextString(m) }
func (*FlushRowsRequest) ProtoMessage()    {}
func (*FlushRowsRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_f4f9d0517c05d712, []int{8}
}

func (m *FlushRowsRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_FlushRowsRequest.Unmarshal(m, b)
}
func (m *FlushRowsRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_FlushRowsRequest.Marshal(b, m, deterministic)
}
func (m *FlushRowsRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_FlushRowsRequest.Merge(m, src)
}
func (m *FlushRowsRequest) XXX_Size() int {
	return xxx_messageInfo_FlushRowsRequest.Size(m)
}
func (m *FlushRowsRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_FlushRowsRequest.DiscardUnknown(m)
}

var xxx_messageInfo_FlushRowsRequest proto.InternalMessageInfo

func (m *FlushRowsRequest) GetWriteStream() string {
	if m != nil {
		return m.WriteStream
	}
	return ""
}

func (m *FlushRowsRequest) GetOffset() int64 {
	if m != nil {
		return m.Offset
	}
	return 0
}

// Respond message for `FlushRows`.
type FlushRowsResponse struct {
	// The rows before this offset (including this offset) are flushed.
	Offset               int64    `protobuf:"varint,1,opt,name=offset,proto3" json:"offset,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *FlushRowsResponse) Reset()         { *m = FlushRowsResponse{} }
func (m *FlushRowsResponse) String() string { return proto.CompactTextString(m) }
func (*FlushRowsResponse) ProtoMessage()    {}
func (*FlushRowsResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_f4f9d0517c05d712, []int{9}
}

func (m *FlushRowsResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_FlushRowsResponse.Unmarshal(m, b)
}
func (m *FlushRowsResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_FlushRowsResponse.Marshal(b, m, deterministic)
}
func (m *FlushRowsResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_FlushRowsResponse.Merge(m, src)
}
func (m *FlushRowsResponse) XXX_Size() int {
	return xxx_messageInfo_FlushRowsResponse.Size(m)
}
func (m *FlushRowsResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_FlushRowsResponse.DiscardUnknown(m)
}

var xxx_messageInfo_FlushRowsResponse proto.InternalMessageInfo

func (m *FlushRowsResponse) GetOffset() int64 {
	if m != nil {
		return m.Offset
	}
	return 0
}

func init() {
	proto.RegisterType((*CreateWriteStreamRequest)(nil), "google.cloud.bigquery.storage.v1alpha2.CreateWriteStreamRequest")
	proto.RegisterType((*AppendRowsRequest)(nil), "google.cloud.bigquery.storage.v1alpha2.AppendRowsRequest")
	proto.RegisterType((*AppendRowsRequest_ProtoData)(nil), "google.cloud.bigquery.storage.v1alpha2.AppendRowsRequest.ProtoData")
	proto.RegisterType((*AppendRowsResponse)(nil), "google.cloud.bigquery.storage.v1alpha2.AppendRowsResponse")
	proto.RegisterType((*GetWriteStreamRequest)(nil), "google.cloud.bigquery.storage.v1alpha2.GetWriteStreamRequest")
	proto.RegisterType((*BatchCommitWriteStreamsRequest)(nil), "google.cloud.bigquery.storage.v1alpha2.BatchCommitWriteStreamsRequest")
	proto.RegisterType((*BatchCommitWriteStreamsResponse)(nil), "google.cloud.bigquery.storage.v1alpha2.BatchCommitWriteStreamsResponse")
	proto.RegisterType((*FinalizeWriteStreamRequest)(nil), "google.cloud.bigquery.storage.v1alpha2.FinalizeWriteStreamRequest")
	proto.RegisterType((*FinalizeWriteStreamResponse)(nil), "google.cloud.bigquery.storage.v1alpha2.FinalizeWriteStreamResponse")
	proto.RegisterType((*FlushRowsRequest)(nil), "google.cloud.bigquery.storage.v1alpha2.FlushRowsRequest")
	proto.RegisterType((*FlushRowsResponse)(nil), "google.cloud.bigquery.storage.v1alpha2.FlushRowsResponse")
}

func init() {
	proto.RegisterFile("google/cloud/bigquery/storage/v1alpha2/storage.proto", fileDescriptor_f4f9d0517c05d712)
}

var fileDescriptor_f4f9d0517c05d712 = []byte{
	// 1025 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xbc, 0x57, 0x4f, 0x6f, 0xdc, 0xc4,
	0x1b, 0xce, 0x64, 0xf3, 0x8b, 0xba, 0x6f, 0xd2, 0x9f, 0xc8, 0x54, 0xb4, 0xc1, 0x41, 0x69, 0x65,
	0xa1, 0x2a, 0x5a, 0x82, 0x4d, 0x36, 0x05, 0x35, 0xa9, 0x8a, 0xf0, 0x6e, 0xd9, 0x06, 0x21, 0x24,
	0x70, 0xca, 0x1f, 0x51, 0xc1, 0x6a, 0xd6, 0x3b, 0xbb, 0x6b, 0x64, 0x7b, 0xdc, 0x99, 0x71, 0xad,
	0x52, 0x71, 0x80, 0x2b, 0x17, 0x24, 0xbe, 0x04, 0x07, 0x0e, 0x7c, 0x01, 0x0e, 0x5c, 0xb9, 0x01,
	0xb7, 0x48, 0x48, 0x3d, 0xf4, 0x82, 0x90, 0xf8, 0x00, 0x9c, 0x90, 0xc7, 0xe3, 0x8d, 0xb3, 0x49,
	0x1a, 0x67, 0x53, 0x7a, 0xcb, 0xce, 0xbc, 0x7f, 0x9e, 0xe7, 0x99, 0x77, 0x9e, 0x71, 0xe0, 0xda,
	0x90, 0xb1, 0x61, 0x40, 0x6d, 0x2f, 0x60, 0x49, 0xdf, 0xee, 0xf9, 0xc3, 0x7b, 0x09, 0xe5, 0x0f,
	0x6c, 0x21, 0x19, 0x27, 0x43, 0x6a, 0xdf, 0xdf, 0x20, 0x41, 0x3c, 0x22, 0xcd, 0x62, 0xc1, 0x8a,
	0x39, 0x93, 0x0c, 0x5f, 0xcd, 0xb3, 0x2c, 0x95, 0x65, 0x15, 0x59, 0x56, 0x11, 0x54, 0x64, 0x19,
	0x2f, 0xea, 0xea, 0x24, 0xf6, 0x6d, 0x12, 0x45, 0x4c, 0x12, 0xe9, 0xb3, 0x48, 0xe4, 0x55, 0x8c,
	0x4b, 0xa5, 0x5d, 0x2f, 0xf0, 0x69, 0x24, 0xf5, 0xc6, 0xe5, 0xd2, 0xc6, 0xc0, 0xa7, 0x41, 0xbf,
	0xdb, 0xa3, 0x23, 0x72, 0xdf, 0x67, 0x5c, 0x07, 0xbc, 0x50, 0x0a, 0xe0, 0x54, 0xb0, 0x84, 0x7b,
	0x1a, 0x9a, 0xf1, 0x5a, 0x45, 0x42, 0x2a, 0xba, 0x97, 0x0c, 0x74, 0xda, 0x66, 0x65, 0x1d, 0x38,
	0x25, 0xa1, 0x4e, 0x6a, 0x56, 0x4c, 0x92, 0xa4, 0x17, 0x14, 0xf8, 0x56, 0x74, 0x4e, 0xd1, 0xdf,
	0xa6, 0x61, 0x2c, 0x1f, 0x4c, 0x10, 0x1f, 0x6f, 0x4a, 0x3f, 0xa4, 0x42, 0x92, 0x30, 0xd6, 0x01,
	0xab, 0x93, 0x01, 0x29, 0x27, 0x71, 0x4c, 0xf9, 0xa4, 0xa4, 0x3c, 0xf6, 0x6c, 0x21, 0x89, 0x4c,
	0xf4, 0x86, 0xf9, 0x13, 0x82, 0xe5, 0x36, 0xa7, 0x44, 0xd2, 0x8f, 0xb8, 0x2f, 0xe9, 0xae, 0xa2,
	0xe1, 0xd2, 0x7b, 0x09, 0x15, 0x12, 0xdf, 0x82, 0xf9, 0x98, 0x70, 0x1a, 0xc9, 0x65, 0x74, 0x05,
	0xad, 0xd5, 0x5b, 0xeb, 0x8f, 0x9c, 0xd9, 0x7f, 0x9c, 0xab, 0xf0, 0x52, 0x41, 0xa9, 0x38, 0xd8,
	0xbc, 0x3a, 0x89, 0x7d, 0x61, 0x79, 0x2c, 0xb4, 0xef, 0x64, 0xbc, 0x5c, 0x9d, 0x8b, 0xef, 0xc2,
	0x62, 0x9a, 0xd5, 0xee, 0xe6, 0x1a, 0x2d, 0xcf, 0x5e, 0x41, 0x6b, 0x0b, 0xcd, 0x4d, 0xab, 0xda,
	0xac, 0x58, 0x25, 0x5c, 0xad, 0xda, 0x23, 0x67, 0xd6, 0x5d, 0x48, 0xf7, 0x57, 0xcc, 0x9f, 0x6b,
	0xb0, 0xe4, 0xc4, 0x31, 0x8d, 0xfa, 0x2e, 0x4b, 0x45, 0x01, 0xfc, 0x83, 0x89, 0x96, 0x39, 0xfc,
	0xa6, 0x82, 0xbf, 0x0e, 0x8d, 0x13, 0xe0, 0x97, 0x95, 0x28, 0x37, 0xc3, 0xd7, 0x61, 0x9e, 0x0d,
	0x06, 0x82, 0x4a, 0xcd, 0x61, 0xa5, 0xe0, 0x30, 0x1e, 0x9a, 0xb7, 0x23, 0xf9, 0xfa, 0xb5, 0x0f,
	0x49, 0x90, 0xd0, 0x0c, 0x2b, 0x72, 0x75, 0x3c, 0xee, 0x03, 0xa8, 0x98, 0x2e, 0x67, 0xa9, 0x58,
	0x9e, 0x53, 0xd9, 0xed, 0xaa, 0x0a, 0x1c, 0xe2, 0x67, 0xbd, 0x97, 0xd5, 0xba, 0x45, 0x24, 0xd9,
	0x99, 0x71, 0xeb, 0xaa, 0x70, 0xb6, 0x6b, 0xfc, 0x80, 0xa0, 0x3e, 0xde, 0xc2, 0x1f, 0xc3, 0x79,
	0x05, 0x9e, 0x77, 0x85, 0x37, 0xa2, 0x21, 0x51, 0x2a, 0x9c, 0x42, 0x78, 0x55, 0x69, 0x57, 0xa5,
	0xba, 0xb9, 0x9c, 0x3c, 0xff, 0x85, 0xdf, 0x82, 0x39, 0xc5, 0x23, 0x57, 0x61, 0xe3, 0x54, 0x05,
	0x15, 0x0d, 0x95, 0xde, 0x9a, 0xcf, 0xcb, 0x98, 0x03, 0xc0, 0x65, 0x8a, 0x22, 0x66, 0x91, 0xa0,
	0x78, 0x79, 0x2c, 0x76, 0x86, 0xbb, 0xb6, 0x33, 0x33, 0x16, 0xb3, 0x01, 0xff, 0xa3, 0x9c, 0x33,
	0xae, 0xfb, 0xe3, 0xa2, 0x3f, 0x8f, 0x3d, 0x6b, 0x57, 0x0d, 0xf7, 0xce, 0x8c, 0x9b, 0x87, 0xb4,
	0x00, 0xce, 0x71, 0x5d, 0xd1, 0xec, 0xc2, 0xf3, 0xb7, 0xa9, 0x3c, 0x62, 0xce, 0x3b, 0x30, 0x17,
	0x91, 0x90, 0x9e, 0x61, 0x4c, 0x54, 0xbe, 0xf9, 0x2d, 0x82, 0xd5, 0x16, 0x91, 0xde, 0xa8, 0xcd,
	0xc2, 0xd0, 0x2f, 0x77, 0x12, 0x4f, 0xf7, 0x4a, 0xad, 0xe9, 0xa3, 0xd5, 0xf3, 0x9d, 0x9d, 0x44,
	0x6d, 0xad, 0x9e, 0x5f, 0x8f, 0xc5, 0xd2, 0xc4, 0x0a, 0xf3, 0x33, 0xb8, 0x7c, 0x2c, 0x22, 0x2d,
	0xf4, 0x0d, 0x58, 0xf0, 0xd4, 0x6e, 0x37, 0x73, 0x15, 0x3d, 0x25, 0xc6, 0xa1, 0xd1, 0xbe, 0x53,
	0x58, 0x8e, 0x0b, 0x79, 0x78, 0xb6, 0x60, 0xf6, 0xc1, 0xe8, 0xf8, 0x11, 0x09, 0xfc, 0x2f, 0xe8,
	0x7f, 0x28, 0xec, 0x36, 0xac, 0x1c, 0xd9, 0x45, 0x33, 0x58, 0x81, 0x3a, 0x67, 0x69, 0xd7, 0x63,
	0x89, 0xd6, 0xb5, 0xe6, 0x9e, 0xe3, 0x2c, 0x6d, 0x67, 0xbf, 0xcd, 0xaf, 0x10, 0x3c, 0xd7, 0x09,
	0x12, 0x31, 0x7a, 0x06, 0x06, 0x71, 0xf1, 0x80, 0x41, 0xd4, 0x8a, 0x89, 0x35, 0x5f, 0x86, 0xa5,
	0x12, 0x04, 0x8d, 0xfa, 0xe2, 0xc1, 0x01, 0x2f, 0x82, 0x9b, 0xdf, 0x2f, 0xc2, 0xf9, 0x96, 0x3f,
	0x7c, 0x3f, 0x03, 0xa0, 0x3a, 0xe1, 0x3f, 0x11, 0x2c, 0x1d, 0x32, 0x69, 0xfc, 0x66, 0xd5, 0x7b,
	0x77, 0x9c, 0xbf, 0x1b, 0xd3, 0x78, 0xb0, 0xf9, 0xe9, 0x9e, 0x73, 0x21, 0x1f, 0xc3, 0xf5, 0xb2,
	0x84, 0x5f, 0xff, 0xfe, 0xf8, 0xbb, 0x59, 0xc7, 0xdc, 0xd8, 0x7f, 0xdd, 0x1e, 0xe6, 0x51, 0x37,
	0x63, 0xce, 0x3e, 0xa7, 0x9e, 0x14, 0x76, 0xc3, 0xee, 0x13, 0x49, 0x04, 0x55, 0x7f, 0xaa, 0xb7,
	0x4f, 0xd8, 0x8d, 0x2f, 0xb7, 0x0f, 0x9c, 0x04, 0x7e, 0x8c, 0x00, 0xf6, 0xdd, 0x00, 0x6f, 0x4d,
	0x6d, 0x92, 0xc6, 0xf6, 0x34, 0xa9, 0xda, 0x2a, 0xee, 0xee, 0x39, 0x8b, 0x87, 0xd8, 0x75, 0x4c,
	0xa7, 0xc4, 0xae, 0xbc, 0x7d, 0x02, 0x47, 0xfd, 0x75, 0xa0, 0xd8, 0xa2, 0xc6, 0x1a, 0x7a, 0x15,
	0xe1, 0x5f, 0x11, 0xfc, 0xff, 0xa0, 0x19, 0xe1, 0x9b, 0x55, 0xf1, 0x1e, 0x69, 0x62, 0xd3, 0x1d,
	0xe6, 0x3b, 0x7b, 0x8e, 0xba, 0x61, 0x8a, 0xdf, 0x1b, 0xe6, 0x56, 0x89, 0x5f, 0xb6, 0x7c, 0x2a,
	0x5e, 0xf8, 0x2f, 0x04, 0x17, 0x8e, 0xb8, 0xa6, 0xb8, 0x55, 0x15, 0xd9, 0xf1, 0x4e, 0x62, 0xb4,
	0xcf, 0x54, 0x43, 0x9f, 0xea, 0x53, 0x65, 0xfb, 0x37, 0x82, 0x4b, 0xc7, 0x58, 0x2b, 0xee, 0x54,
	0x45, 0xfb, 0xe4, 0xd7, 0xc2, 0xb8, 0x7d, 0xe6, 0x3a, 0x9a, 0x79, 0x6b, 0xcf, 0xd1, 0x6f, 0x87,
	0xe2, 0xbe, 0x89, 0x4f, 0x7f, 0x4f, 0xf1, 0x1f, 0x08, 0xea, 0x63, 0x17, 0xc3, 0xd7, 0x2b, 0x1f,
	0xc8, 0x84, 0xf7, 0x1a, 0x5b, 0x53, 0x64, 0x3e, 0x83, 0x6b, 0x69, 0xfc, 0x88, 0x7e, 0x71, 0x56,
	0x9f, 0xec, 0xfc, 0xbf, 0x39, 0xdf, 0xa0, 0x91, 0x94, 0xb1, 0xd8, 0xb6, 0xed, 0x34, 0x4d, 0x27,
	0xdf, 0x05, 0x92, 0xc8, 0xd1, 0xf8, 0x73, 0x7f, 0xbd, 0x6a, 0xa0, 0xe5, 0x47, 0x82, 0x72, 0x99,
	0x01, 0x3c, 0x31, 0x47, 0x49, 0xf6, 0x4a, 0x1c, 0x10, 0x39, 0x60, 0x3c, 0x6c, 0x3d, 0x84, 0x86,
	0xc7, 0xc2, 0x8a, 0x7a, 0x7e, 0xf2, 0xae, 0x8e, 0x1b, 0xb2, 0x80, 0x44, 0x43, 0x8b, 0xf1, 0xa1,
	0x3d, 0xa4, 0x91, 0x7a, 0xe0, 0xed, 0xfd, 0x66, 0x27, 0xfd, 0xd7, 0x72, 0x43, 0x2f, 0xf4, 0xe6,
	0x55, 0xe6, 0xe6, 0xbf, 0x01, 0x00, 0x00, 0xff, 0xff, 0x0d, 0x00, 0x40, 0x19, 0x2b, 0x0e, 0x00,
	0x00,
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConnInterface

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion6

// BigQueryWriteClient is the client API for BigQueryWrite service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type BigQueryWriteClient interface {
	// Creates a write stream to the given table.
	CreateWriteStream(ctx context.Context, in *CreateWriteStreamRequest, opts ...grpc.CallOption) (*WriteStream, error)
	// Appends data to the given stream.
	//
	// If `offset` is specified, the `offset` is checked against the end of
	// stream. The server returns `OUT_OF_RANGE` in `AppendRowsResponse` if an
	// attempt is made to append to an offset beyond the current end of the stream
	// or `ALREADY_EXISTS` if user provids an `offset` that has already been
	// written to. User can retry with adjusted offset within the same RPC
	// stream. If `offset` is not specified, append happens at the end of the
	// stream.
	//
	// The response contains the offset at which the append happened. Responses
	// are received in the same order in which requests are sent. There will be
	// one response for each successful request. If the `offset` is not set in
	// response, it means append didn't happen due to some errors. If one request
	// fails, all the subsequent requests will also fail until a success request
	// is made again.
	//
	// If the stream is of `PENDING` type, data will only be available for read
	// operations after the stream is committed.
	AppendRows(ctx context.Context, opts ...grpc.CallOption) (BigQueryWrite_AppendRowsClient, error)
	// Gets a write stream.
	GetWriteStream(ctx context.Context, in *GetWriteStreamRequest, opts ...grpc.CallOption) (*WriteStream, error)
	// Finalize a write stream so that no new data can be appended to the
	// stream.
	FinalizeWriteStream(ctx context.Context, in *FinalizeWriteStreamRequest, opts ...grpc.CallOption) (*FinalizeWriteStreamResponse, error)
	// Atomically commits a group of `PENDING` streams that belong to the same
	// `parent` table.
	// Streams must be finalized before commit and cannot be committed multiple
	// times. Once a stream is committed, data in the stream becomes available
	// for read operations.
	BatchCommitWriteStreams(ctx context.Context, in *BatchCommitWriteStreamsRequest, opts ...grpc.CallOption) (*BatchCommitWriteStreamsResponse, error)
	// Flushes rows to a BUFFERED stream.
	// If users are appending rows to BUFFERED stream, flush operation is
	// required in order for the rows to become available for reading. A
	// Flush operation flushes up to any previously flushed offset in a BUFFERED
	// stream, to the offset specified in the request.
	FlushRows(ctx context.Context, in *FlushRowsRequest, opts ...grpc.CallOption) (*FlushRowsResponse, error)
}

type bigQueryWriteClient struct {
	cc grpc.ClientConnInterface
}

func NewBigQueryWriteClient(cc grpc.ClientConnInterface) BigQueryWriteClient {
	return &bigQueryWriteClient{cc}
}

func (c *bigQueryWriteClient) CreateWriteStream(ctx context.Context, in *CreateWriteStreamRequest, opts ...grpc.CallOption) (*WriteStream, error) {
	out := new(WriteStream)
	err := c.cc.Invoke(ctx, "/google.cloud.bigquery.storage.v1alpha2.BigQueryWrite/CreateWriteStream", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *bigQueryWriteClient) AppendRows(ctx context.Context, opts ...grpc.CallOption) (BigQueryWrite_AppendRowsClient, error) {
	stream, err := c.cc.NewStream(ctx, &_BigQueryWrite_serviceDesc.Streams[0], "/google.cloud.bigquery.storage.v1alpha2.BigQueryWrite/AppendRows", opts...)
	if err != nil {
		return nil, err
	}
	x := &bigQueryWriteAppendRowsClient{stream}
	return x, nil
}

type BigQueryWrite_AppendRowsClient interface {
	Send(*AppendRowsRequest) error
	Recv() (*AppendRowsResponse, error)
	grpc.ClientStream
}

type bigQueryWriteAppendRowsClient struct {
	grpc.ClientStream
}

func (x *bigQueryWriteAppendRowsClient) Send(m *AppendRowsRequest) error {
	return x.ClientStream.SendMsg(m)
}

func (x *bigQueryWriteAppendRowsClient) Recv() (*AppendRowsResponse, error) {
	m := new(AppendRowsResponse)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

func (c *bigQueryWriteClient) GetWriteStream(ctx context.Context, in *GetWriteStreamRequest, opts ...grpc.CallOption) (*WriteStream, error) {
	out := new(WriteStream)
	err := c.cc.Invoke(ctx, "/google.cloud.bigquery.storage.v1alpha2.BigQueryWrite/GetWriteStream", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *bigQueryWriteClient) FinalizeWriteStream(ctx context.Context, in *FinalizeWriteStreamRequest, opts ...grpc.CallOption) (*FinalizeWriteStreamResponse, error) {
	out := new(FinalizeWriteStreamResponse)
	err := c.cc.Invoke(ctx, "/google.cloud.bigquery.storage.v1alpha2.BigQueryWrite/FinalizeWriteStream", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *bigQueryWriteClient) BatchCommitWriteStreams(ctx context.Context, in *BatchCommitWriteStreamsRequest, opts ...grpc.CallOption) (*BatchCommitWriteStreamsResponse, error) {
	out := new(BatchCommitWriteStreamsResponse)
	err := c.cc.Invoke(ctx, "/google.cloud.bigquery.storage.v1alpha2.BigQueryWrite/BatchCommitWriteStreams", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *bigQueryWriteClient) FlushRows(ctx context.Context, in *FlushRowsRequest, opts ...grpc.CallOption) (*FlushRowsResponse, error) {
	out := new(FlushRowsResponse)
	err := c.cc.Invoke(ctx, "/google.cloud.bigquery.storage.v1alpha2.BigQueryWrite/FlushRows", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// BigQueryWriteServer is the server API for BigQueryWrite service.
type BigQueryWriteServer interface {
	// Creates a write stream to the given table.
	CreateWriteStream(context.Context, *CreateWriteStreamRequest) (*WriteStream, error)
	// Appends data to the given stream.
	//
	// If `offset` is specified, the `offset` is checked against the end of
	// stream. The server returns `OUT_OF_RANGE` in `AppendRowsResponse` if an
	// attempt is made to append to an offset beyond the current end of the stream
	// or `ALREADY_EXISTS` if user provids an `offset` that has already been
	// written to. User can retry with adjusted offset within the same RPC
	// stream. If `offset` is not specified, append happens at the end of the
	// stream.
	//
	// The response contains the offset at which the append happened. Responses
	// are received in the same order in which requests are sent. There will be
	// one response for each successful request. If the `offset` is not set in
	// response, it means append didn't happen due to some errors. If one request
	// fails, all the subsequent requests will also fail until a success request
	// is made again.
	//
	// If the stream is of `PENDING` type, data will only be available for read
	// operations after the stream is committed.
	AppendRows(BigQueryWrite_AppendRowsServer) error
	// Gets a write stream.
	GetWriteStream(context.Context, *GetWriteStreamRequest) (*WriteStream, error)
	// Finalize a write stream so that no new data can be appended to the
	// stream.
	FinalizeWriteStream(context.Context, *FinalizeWriteStreamRequest) (*FinalizeWriteStreamResponse, error)
	// Atomically commits a group of `PENDING` streams that belong to the same
	// `parent` table.
	// Streams must be finalized before commit and cannot be committed multiple
	// times. Once a stream is committed, data in the stream becomes available
	// for read operations.
	BatchCommitWriteStreams(context.Context, *BatchCommitWriteStreamsRequest) (*BatchCommitWriteStreamsResponse, error)
	// Flushes rows to a BUFFERED stream.
	// If users are appending rows to BUFFERED stream, flush operation is
	// required in order for the rows to become available for reading. A
	// Flush operation flushes up to any previously flushed offset in a BUFFERED
	// stream, to the offset specified in the request.
	FlushRows(context.Context, *FlushRowsRequest) (*FlushRowsResponse, error)
}

// UnimplementedBigQueryWriteServer can be embedded to have forward compatible implementations.
type UnimplementedBigQueryWriteServer struct {
}

func (*UnimplementedBigQueryWriteServer) CreateWriteStream(ctx context.Context, req *CreateWriteStreamRequest) (*WriteStream, error) {
	return nil, status1.Errorf(codes.Unimplemented, "method CreateWriteStream not implemented")
}
func (*UnimplementedBigQueryWriteServer) AppendRows(srv BigQueryWrite_AppendRowsServer) error {
	return status1.Errorf(codes.Unimplemented, "method AppendRows not implemented")
}
func (*UnimplementedBigQueryWriteServer) GetWriteStream(ctx context.Context, req *GetWriteStreamRequest) (*WriteStream, error) {
	return nil, status1.Errorf(codes.Unimplemented, "method GetWriteStream not implemented")
}
func (*UnimplementedBigQueryWriteServer) FinalizeWriteStream(ctx context.Context, req *FinalizeWriteStreamRequest) (*FinalizeWriteStreamResponse, error) {
	return nil, status1.Errorf(codes.Unimplemented, "method FinalizeWriteStream not implemented")
}
func (*UnimplementedBigQueryWriteServer) BatchCommitWriteStreams(ctx context.Context, req *BatchCommitWriteStreamsRequest) (*BatchCommitWriteStreamsResponse, error) {
	return nil, status1.Errorf(codes.Unimplemented, "method BatchCommitWriteStreams not implemented")
}
func (*UnimplementedBigQueryWriteServer) FlushRows(ctx context.Context, req *FlushRowsRequest) (*FlushRowsResponse, error) {
	return nil, status1.Errorf(codes.Unimplemented, "method FlushRows not implemented")
}

func RegisterBigQueryWriteServer(s *grpc.Server, srv BigQueryWriteServer) {
	s.RegisterService(&_BigQueryWrite_serviceDesc, srv)
}

func _BigQueryWrite_CreateWriteStream_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(CreateWriteStreamRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(BigQueryWriteServer).CreateWriteStream(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/google.cloud.bigquery.storage.v1alpha2.BigQueryWrite/CreateWriteStream",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(BigQueryWriteServer).CreateWriteStream(ctx, req.(*CreateWriteStreamRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _BigQueryWrite_AppendRows_Handler(srv interface{}, stream grpc.ServerStream) error {
	return srv.(BigQueryWriteServer).AppendRows(&bigQueryWriteAppendRowsServer{stream})
}

type BigQueryWrite_AppendRowsServer interface {
	Send(*AppendRowsResponse) error
	Recv() (*AppendRowsRequest, error)
	grpc.ServerStream
}

type bigQueryWriteAppendRowsServer struct {
	grpc.ServerStream
}

func (x *bigQueryWriteAppendRowsServer) Send(m *AppendRowsResponse) error {
	return x.ServerStream.SendMsg(m)
}

func (x *bigQueryWriteAppendRowsServer) Recv() (*AppendRowsRequest, error) {
	m := new(AppendRowsRequest)
	if err := x.ServerStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

func _BigQueryWrite_GetWriteStream_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetWriteStreamRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(BigQueryWriteServer).GetWriteStream(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/google.cloud.bigquery.storage.v1alpha2.BigQueryWrite/GetWriteStream",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(BigQueryWriteServer).GetWriteStream(ctx, req.(*GetWriteStreamRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _BigQueryWrite_FinalizeWriteStream_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(FinalizeWriteStreamRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(BigQueryWriteServer).FinalizeWriteStream(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/google.cloud.bigquery.storage.v1alpha2.BigQueryWrite/FinalizeWriteStream",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(BigQueryWriteServer).FinalizeWriteStream(ctx, req.(*FinalizeWriteStreamRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _BigQueryWrite_BatchCommitWriteStreams_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(BatchCommitWriteStreamsRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(BigQueryWriteServer).BatchCommitWriteStreams(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/google.cloud.bigquery.storage.v1alpha2.BigQueryWrite/BatchCommitWriteStreams",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(BigQueryWriteServer).BatchCommitWriteStreams(ctx, req.(*BatchCommitWriteStreamsRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _BigQueryWrite_FlushRows_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(FlushRowsRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(BigQueryWriteServer).FlushRows(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/google.cloud.bigquery.storage.v1alpha2.BigQueryWrite/FlushRows",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(BigQueryWriteServer).FlushRows(ctx, req.(*FlushRowsRequest))
	}
	return interceptor(ctx, in, info, handler)
}

var _BigQueryWrite_serviceDesc = grpc.ServiceDesc{
	ServiceName: "google.cloud.bigquery.storage.v1alpha2.BigQueryWrite",
	HandlerType: (*BigQueryWriteServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "CreateWriteStream",
			Handler:    _BigQueryWrite_CreateWriteStream_Handler,
		},
		{
			MethodName: "GetWriteStream",
			Handler:    _BigQueryWrite_GetWriteStream_Handler,
		},
		{
			MethodName: "FinalizeWriteStream",
			Handler:    _BigQueryWrite_FinalizeWriteStream_Handler,
		},
		{
			MethodName: "BatchCommitWriteStreams",
			Handler:    _BigQueryWrite_BatchCommitWriteStreams_Handler,
		},
		{
			MethodName: "FlushRows",
			Handler:    _BigQueryWrite_FlushRows_Handler,
		},
	},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "AppendRows",
			Handler:       _BigQueryWrite_AppendRows_Handler,
			ServerStreams: true,
			ClientStreams: true,
		},
	},
	Metadata: "google/cloud/bigquery/storage/v1alpha2/storage.proto",
}
